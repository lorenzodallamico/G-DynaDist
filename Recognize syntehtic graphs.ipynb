{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8529522c",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "In this notebook we generate some random graphs from $4$ different families (Erdos-Renyi, stochastic block model, configuration model and geometric model) and make them temporal associating to each edge a temporal series of an edge of the *SP* called `SFHH`. Each graph has a varying number of nodes. We then use our distance definition to cluster the graphs according to their generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a959934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path += ['Package']\n",
    "\n",
    "from MatrixDistance import *\n",
    "from GraphCreation import *\n",
    "from Utilities import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3084ae8",
   "metadata": {},
   "source": [
    "### Get the daily activity patterns for each edge in `SFHH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde9bd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\r"
     ]
    }
   ],
   "source": [
    "# # we build df_SP so that it contains (i,j,t, day)\n",
    "# df_SP = pd.read_csv('../Codes/Data/SPData/SFHH.dat', header = None, sep = ' ', names = ['t', 'i', 'j'])\n",
    "# df_SP['day'] = pd.to_datetime(df_SP.t, unit = 's')\n",
    "# df_SP['day'] = df_SP.day.dt.day\n",
    "# all_pairs = df_SP.groupby(['i', 'j', 'day']).size().reset_index()[['i', 'j', 'day']].values\n",
    "# df_SP.set_index(['i', 'j', 'day'], inplace = True)\n",
    "\n",
    "# timeF = []\n",
    "\n",
    "# # a pair is in the form (i, j, day) and timeF stores all the interactions between i and j on day t\n",
    "# for x, pair in enumerate(all_pairs):\n",
    "#     print(str(np.round((x+1)/len(all_pairs)*100,2)) + ' %', end = '\\r')\n",
    "#     i, j, t = pair\n",
    "#     timeF.append(df_SP.loc[i, j, t].t.values)\n",
    "    \n",
    "# # we then construct time FR that for each (i,j,t) stores the edge time-line, centered to 00:00 of the corresponding day \n",
    "# timeFR = [[] for x in range(len(timeF))]\n",
    "\n",
    "# for a, T in enumerate(timeF):\n",
    "#     print(str(np.round((a+1)/len(all_pairs)*100,2)) + ' %', end = '\\r')\n",
    "#     for t in T:\n",
    "#         if (pd.to_datetime(t, unit = 's') - pd.to_datetime('1970-01-01 08:00:00')).days == 1:\n",
    "\n",
    "#             tt = (pd.to_datetime(t, unit = 's') - pd.to_datetime('1970-01-02 08:00:00')).total_seconds()\n",
    "            \n",
    "#         else:\n",
    "#             tt = (pd.to_datetime(t, unit = 's') - pd.to_datetime('1970-01-01 08:00:00')).total_seconds()\n",
    "            \n",
    "#         timeFR[a].append(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ad2cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n",
      "\n",
      "100.0 %\n",
      "\n",
      "100.0 %\n",
      "\n",
      "100.0 %\r"
     ]
    }
   ],
   "source": [
    "# # We generate a sequence of temporal graphs with n0 = 1000 as the average number of nodes and store them in the \n",
    "# # list DFT. For each type we generate 250 graphs\n",
    "\n",
    "# n0 = 1000\n",
    "# n_graphs = 250\n",
    "\n",
    "# # variance of the graph size\n",
    "# γ = 0.8\n",
    "\n",
    "# DFT = []\n",
    "# size = []\n",
    "\n",
    "# ### DCSBM\n",
    "# k = 5\n",
    "# c_in = 25\n",
    "# c_out = 1\n",
    "# C = np.ones((k,k))*c_out\n",
    "# C += np.diag(np.ones(k))*(c_in - c_out)\n",
    "# c = (c_in + (k-1)*c_out)/k\n",
    "# symmetric = True\n",
    "# make_connected = True\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(n_graphs):\n",
    "#     print(str(100*(i+1)/n_graphs) + ' %' , end = '\\r')\n",
    "    \n",
    "#     n = np.random.randint(int(n0*(1-γ)), int(n0*(1+γ)))\n",
    "#     θ = np.ones(n)\n",
    "#     ℓ = np.zeros(n)\n",
    "#     for i in range(k):\n",
    "#         ℓ[i*int(n/k): (i+1)*int(n/k)] = i\n",
    "#     ℓ = ℓ.astype(int)\n",
    "\n",
    "#     args = (C, c, ℓ, θ, symmetric, make_connected)\n",
    "#     dft = DCSBM(args)\n",
    "#     DFT.append(MakeTemporal(dft, timeFR))\n",
    "#     size.append(n)\n",
    "# print('\\n')\n",
    "    \n",
    "# ### ER\n",
    "# k = 1\n",
    "# C = np.ones((k,k))*c\n",
    "\n",
    "# for i in range(n_graphs):\n",
    "#     print(str(100*(i+1)/n_graphs) + ' %' , end = '\\r')\n",
    "    \n",
    "#     n = np.random.randint(int(n0*(1-γ)), int(n0*(1+γ)))\n",
    "#     ℓ = np.zeros(n).astype(int)\n",
    "#     θ = np.ones(n)\n",
    "#     args = (C, c, ℓ, θ, symmetric, make_connected)\n",
    "\n",
    "#     dft = DCSBM(args)\n",
    "#     DFT.append(MakeTemporal(dft, timeFR))\n",
    "#     size.append(n)\n",
    "# print('\\n')\n",
    "\n",
    "    \n",
    "# ### Configuration model\n",
    "# for i in range(n_graphs):\n",
    "#     print(str(100*(i+1)/n_graphs) + ' %' , end = '\\r')\n",
    "    \n",
    "#     n = np.random.randint(int(n0*(1-γ)), int(n0*(1+γ)))\n",
    "#     θ = np.random.uniform(3,10, n)**4\n",
    "#     θ = θ/np.mean(θ)\n",
    "#     ℓ = np.zeros(n).astype(int)\n",
    "#     args = (C, c, ℓ, θ, symmetric, make_connected)\n",
    "\n",
    "    \n",
    "#     dft = DCSBM(args)\n",
    "#     DFT.append(MakeTemporal(dft, timeFR))\n",
    "#     size.append(n)\n",
    "# print('\\n')\n",
    "\n",
    "# ### Geometric model\n",
    "# β = 20\n",
    "\n",
    "# for i in range(n_graphs):\n",
    "#     print(str(100*(i+1)/n_graphs) + ' %' , end = '\\r')\n",
    "    \n",
    "#     n = np.random.randint(int(n0*(1-γ)), int(n0*(1+γ)))\n",
    "    \n",
    "#     r = np.random.uniform(0, 1, n)\n",
    "#     θ = np.random.uniform(0, 2*np.pi, n)\n",
    "#     X = np.zeros((n, 2))\n",
    "#     X[:,0] = r*np.cos(θ)\n",
    "#     X[:,1] = r*np.sin(θ)\n",
    "#     args = (X, c, β)\n",
    "\n",
    "    \n",
    "#     dft = GeometricModel(args)\n",
    "#     DFT.append(MakeTemporal(dft, timeFR))\n",
    "    \n",
    "#     size.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4505e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "\n",
      "6400/1000\n",
      "\n",
      "3200/1000\n",
      "\n",
      "1600/1000\n",
      "\n",
      "8000/1000\n",
      "\n",
      "4000/1000\n",
      "\n",
      "2000/1000\n",
      "\n",
      "1000/1000\r"
     ]
    }
   ],
   "source": [
    "# generate the embedding of the temporal graphs\n",
    "\n",
    "dv = [2**(i+1) for i in range(7)]\n",
    "\n",
    "n = len(DFT)\n",
    "\n",
    "for d in dv[::-1]:\n",
    "    print(d, end = '\\r')\n",
    "    print('\\n')\n",
    "\n",
    "    λlist = []\n",
    "\n",
    "    for i in range(n):\n",
    "        print(str(i+1) + '/' + str(n), end = '\\r')\n",
    "        N = len(np.unique(DFT[i][['i', 'j']]))\n",
    "        X = GraphDynamicEmbedding(DFT[i], dim = d, n = N, n_epochs = 20, η = 1, verbose = False)\n",
    "        s, _ = np.shape(X)\n",
    "        λlist.append(np.linalg.eigvalsh(X.T@X)/s)\n",
    "\n",
    "    np.savetxt('Data/Embeddings/Synthetic/embs_' + str(d) + '.txt', λlist)\n",
    "    np.savetxt('Data/Embeddings/Synthetic/size_' + str(d) + '.txt', size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1fa580c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: 2; nmi: 0.3851297874478421\n",
      "d: 4; nmi: 0.6893956958133541\n",
      "d: 8; nmi: 0.9999999999999987\n",
      "d: 16; nmi: 0.9915914875392966\n",
      "d: 32; nmi: 0.9915914875392966\n",
      "d: 64; nmi: 0.9915914875392966\n",
      "d: 128; nmi: 0.9915914875392966\n"
     ]
    }
   ],
   "source": [
    "# perform clustering\n",
    "\n",
    "dv = [2**(i+1) for i in range(7)]\n",
    "n_graphs = 250\n",
    "ℓ = np.concatenate([[i for x in range(n_graphs)] for i in range(4)])\n",
    "nmi_v = []\n",
    "\n",
    "for d in dv:\n",
    "    print(d, end = '\\r')\n",
    "    \n",
    "    # load the embedding\n",
    "    λlist = np.loadtxt('Data/Embeddings/Synthetic/embs_' + str(d) + '.txt')\n",
    "    size = np.loadtxt('Data/Embeddings/Synthetic/size_' + str(d) + '.txt')\n",
    "\n",
    "    # ground truth\n",
    "    gt = np.concatenate([[i for x in range(n_graphs)] for i in range(4)])\n",
    "\n",
    "    k = len(np.unique(gt))\n",
    "\n",
    "    # matrix distance\n",
    "    n, d = λlist.shape\n",
    "    D = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        print(i, end = '\\r')\n",
    "        for j in range(i+1,n):\n",
    "            D[i,j] = np.linalg.norm(λlist[i] - λlist[j])\n",
    "\n",
    "    D = D + D.T\n",
    "    s = NMI(ClusterNMF(D, k), ℓ)\n",
    "    \n",
    "    print(f'd: {d}; nmi: {s}')\n",
    "    nmi_v.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a87611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('Data/Embeddings/Synthetic/vary_d.dat', np.array([dv, nmi_v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a3e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
